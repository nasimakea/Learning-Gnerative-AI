{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\nasim_anaconda\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\nasim_anaconda\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\nasim_anaconda\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\nasim_anaconda\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\nasim_anaconda\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\nasim_anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\nasim_anaconda\\lib\\site-packages\\diamondpriceprediction-0.0.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\nasim_anaconda\\lib\\site-packages\\diamond_price_prediction-3.12.14-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nasim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Heloo welocmee, to krish naik's nlp tutorials.\n",
    "Please do watch the entire course! to become expert in NLP.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heloo welocmee, to krish naik's nlp tutorials.\n",
      "Please do watch the entire course! to become expert in NLP.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "#setnece --> paragraphs\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Heloo welocmee, to krish naik's nlp tutorials.\", 'Please do watch the entire course!', 'to become expert in NLP.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document=sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heloo welocmee, to krish naik's nlp tutorials.\n",
      "Please do watch the entire course!\n",
      "to become expert in NLP.\n"
     ]
    }
   ],
   "source": [
    "for senttence in document:\n",
    "    print(senttence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "# paragraphs --> words\n",
    "# setrnce --> words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heloo',\n",
       " 'welocmee',\n",
       " ',',\n",
       " 'to',\n",
       " 'krish',\n",
       " 'naik',\n",
       " \"'s\",\n",
       " 'nlp',\n",
       " 'tutorials',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Heloo', 'welocmee', ',', 'to', 'krish', 'naik', \"'s\", 'nlp', 'tutorials', '.']\n",
      "['Please', 'do', 'watch', 'the', 'entire', 'course', '!']\n",
      "['to', 'become', 'expert', 'in', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in document:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heloo',\n",
       " 'welocmee',\n",
       " ',',\n",
       " 'to',\n",
       " 'krish',\n",
       " 'naik',\n",
       " \"'\",\n",
       " 's',\n",
       " 'nlp',\n",
       " 'tutorials',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heloo',\n",
       " 'welocmee',\n",
       " ',',\n",
       " 'to',\n",
       " 'krish',\n",
       " 'naik',\n",
       " \"'s\",\n",
       " 'nlp',\n",
       " 'tutorials.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_text = \"\"\"\n",
    "Natural Language Processing (NLP) is a subfield of AI. It focuses on the interaction between computers and humans using natural language. \n",
    "Tokenization is the first step in NLP. It involves splitting text into words or sentences.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'AI',\n",
       " '.',\n",
       " 'It',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'the',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'humans',\n",
       " 'using',\n",
       " 'natural',\n",
       " 'language',\n",
       " '.',\n",
       " 'Tokenization',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'step',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'splitting',\n",
       " 'text',\n",
       " 'into',\n",
       " 'words',\n",
       " 'or',\n",
       " 'sentences',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(large_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nNatural Language Processing (NLP) is a subfield of AI.',\n",
       " 'It focuses on the interaction between computers and humans using natural language.',\n",
       " 'Tokenization is the first step in NLP.',\n",
       " 'It involves splitting text into words or sentences.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(large_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nNatural Language Processing (NLP) is a subfield of AI.',\n",
       " 'It focuses on the interaction between computers and humans using natural language.',\n",
       " 'Tokenization is the first step in NLP.',\n",
       " 'It involves splitting text into words or sentences.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PunktSentenceTokenizer().tokenize(large_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word=word_tokenize(large_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "Language\n",
      "Processing\n",
      "(\n",
      "NLP\n",
      ")\n",
      "is\n",
      "a\n",
      "subfield\n",
      "of\n",
      "AI\n",
      ".\n",
      "It\n",
      "focuses\n",
      "on\n",
      "the\n",
      "interaction\n",
      "between\n",
      "computers\n",
      "and\n",
      "humans\n",
      "using\n",
      "natural\n",
      "language\n",
      ".\n",
      "Tokenization\n",
      "is\n",
      "the\n",
      "first\n",
      "step\n",
      "in\n",
      "NLP\n",
      ".\n",
      "It\n",
      "involves\n",
      "splitting\n",
      "text\n",
      "into\n",
      "words\n",
      "or\n",
      "sentences\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in word:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sentence is : \n",
      "Natural Language Processing (NLP) is a subfield of AI.\n",
      "2 sentence is : It focuses on the interaction between computers and humans using natural language.\n",
      "3 sentence is : Tokenization is the first step in NLP.\n",
      "4 sentence is : It involves splitting text into words or sentences.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(large_text)\n",
    "i=0\n",
    "while i<len(sent_tokenize(large_text)):\n",
    "    print(f\"{i+1} sentence is : {sent_tokenize(large_text)[i]}\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence is \n",
      "Natural Language Processing (NLP) is a subfield of AI.\n",
      "Natural\n",
      "Language\n",
      "Processing\n",
      "(\n",
      "NLP\n",
      ")\n",
      "is\n",
      "a\n",
      "subfield\n",
      "of\n",
      "AI\n",
      ".\n",
      "sentence is It focuses on the interaction between computers and humans using natural language.\n",
      "It\n",
      "focuses\n",
      "on\n",
      "the\n",
      "interaction\n",
      "between\n",
      "computers\n",
      "and\n",
      "humans\n",
      "using\n",
      "natural\n",
      "language\n",
      ".\n",
      "sentence is Tokenization is the first step in NLP.\n",
      "Tokenization\n",
      "is\n",
      "the\n",
      "first\n",
      "step\n",
      "in\n",
      "NLP\n",
      ".\n",
      "sentence is It involves splitting text into words or sentences.\n",
      "It\n",
      "involves\n",
      "splitting\n",
      "text\n",
      "into\n",
      "words\n",
      "or\n",
      "sentences\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for sentence in sent_tokenize(large_text):\n",
    "    print(f\"sentence is {sentence}\")\n",
    "\n",
    "    word=word_tokenize(sentence)\n",
    "    for i in word:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sentence is : \n",
      "Natural Language Processing (NLP) is a subfield of AI.\n",
      "1 word is : Natural\n",
      "2 word is : Language\n",
      "3 word is : Processing\n",
      "4 word is : (\n",
      "5 word is : NLP\n",
      "6 word is : )\n",
      "7 word is : is\n",
      "8 word is : a\n",
      "9 word is : subfield\n",
      "10 word is : of\n",
      "11 word is : AI\n",
      "2 sentence is : It focuses on the interaction between computers and humans using natural language.\n",
      "1 word is : It\n",
      "2 word is : focuses\n",
      "3 word is : on\n",
      "4 word is : the\n",
      "5 word is : interaction\n",
      "6 word is : between\n",
      "7 word is : computers\n",
      "8 word is : and\n",
      "9 word is : humans\n",
      "10 word is : using\n",
      "11 word is : natural\n",
      "12 word is : language\n",
      "3 sentence is : Tokenization is the first step in NLP.\n",
      "1 word is : Tokenization\n",
      "2 word is : is\n",
      "3 word is : the\n",
      "4 word is : first\n",
      "5 word is : step\n",
      "6 word is : in\n",
      "7 word is : NLP\n",
      "4 sentence is : It involves splitting text into words or sentences.\n",
      "1 word is : It\n",
      "2 word is : involves\n",
      "3 word is : splitting\n",
      "4 word is : text\n",
      "5 word is : into\n",
      "6 word is : words\n",
      "7 word is : or\n",
      "8 word is : sentences\n"
     ]
    }
   ],
   "source": [
    "sentence=sent_tokenize(large_text)\n",
    "i=0\n",
    "while i<len(sentence):\n",
    "    print(f\"{i+1} sentence is : {sentence[i]}\")\n",
    "    for j in range(len(word_tokenize(sentence[i]))-1):\n",
    "        print(f\"{j+1} word is : {word_tokenize(sentence[i])[j]}\")\n",
    "\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
